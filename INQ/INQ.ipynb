{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand digit classifier \n",
    "---\n",
    "## Incremental network quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBounderyExponents(W, b):\n",
    "    s = torch.max(torch.abs(W)).item()\n",
    "    n1 = np.floor(np.log2(4*(s/3)))\n",
    "    n2 = n1 + 1 - (2**(b - 1))/2\n",
    "    return n1, n2\n",
    "\n",
    "def getQuantizationMask(W, percentage, T):\n",
    "    w = W.view(-1)\n",
    "    t = T.view(-1)\n",
    "    idx = t == 1\n",
    "\n",
    "    numberOfWeights = w.size(dim=0)\n",
    "    numberOfQWeights = int(percentage*numberOfWeights - t[idx].size(dim=0))\n",
    "\n",
    "    t_aux = torch.Tensor(np.ones_like(T)).view(-1)\n",
    "    w = w*(t_aux - t)\n",
    "    w = torch.abs(w)\n",
    "    sorted_w, indices_w = w.sort()\n",
    "    print(w, sorted_w, indices_w)\n",
    "    t[indices_w[-numberOfQWeights:]] = 1\n",
    "    \n",
    "    return t.view(T.size())\n",
    "\n",
    "def indexTensor(tensor, map):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.tensor(np.array([\n",
    "    [0.01, 0.02, -0.2, 0.04, 0.33],\n",
    "    [0.17, -0.42, -0.33, 0.02, -0.05], \n",
    "    [0.02, 0.83, -0.03, 0.03, 0.06],\n",
    "    [-0.9, 0.07, 0.11, 0.87, -0.36], \n",
    "    [-0.73, 0.41, 0.42, 0.39, 0.47]]))\n",
    "bit_length = 4\n",
    "n1, n2 = getBounderyExponents(W, bit_length)\n",
    "print(n1, n2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 2.0000, 2.0000, 2.0000, 3.0000, 0.5000, 4.0000, 3.0000, 2.0000]) tensor([0.5000, 1.0000, 2.0000, 2.0000, 2.0000, 2.0000, 3.0000, 3.0000, 4.0000]) tensor([5, 0, 1, 2, 3, 8, 4, 7, 6])\n",
      "tensor([[-1.0000,  2.0000, -2.0000],\n",
      "        [ 2.0000,  3.0000, -0.5000],\n",
      "        [ 4.0000,  3.0000,  2.0000]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "percentage = 0.5\n",
    "W = torch.Tensor(np.array([[-1, 2, -2], [2, 3, -0.5], [4, 3, 2]]))\n",
    "T = torch.Tensor(np.zeros_like(W))\n",
    "w = W.view(-1)\n",
    "t = T.view(-1)\n",
    "idx = t == 1\n",
    "\n",
    "numberOfWeights = w.size(dim=0)\n",
    "numberOfQWeights = int(percentage*numberOfWeights - t[idx].size(dim=0))\n",
    "\n",
    "t_aux = torch.Tensor(np.ones_like(T)).view(-1)\n",
    "w = w*(t_aux - t)\n",
    "w = torch.abs(w)\n",
    "sorted_w, indices_w = w.sort()\n",
    "print(w, sorted_w, indices_w)\n",
    "t[indices_w[-numberOfQWeights:]] = 1\n",
    "\n",
    "T = t.view(T.size())\n",
    "print(W)\n",
    "print(T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da9c6a45712c6b513c4a80738271fc65c25531d6aa017375b96d9ba6472bbc68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
