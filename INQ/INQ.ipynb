{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand digit classifier \n",
    "---\n",
    "## Incremental network quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from skimage import io"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(root='../', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.MNIST(root=\"../\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_set = [train_data[i] for i in range(50000)]\n",
    "validation_set = [train_data[i] for i in range(50000, 60000)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=64, shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definig a VGG-7 inspired architecture model\n",
    "---\n",
    "Featuring 4 convolutional and 3 fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG7(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG7, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, padding=\"same\", stride=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=\"same\", stride=1, bias=False)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=\"same\", stride=1, bias=False)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding=\"same\", stride=1, bias=False)\n",
    "        \n",
    "        self.fc1 = nn.Linear(7*7*128, 512, bias=False)\n",
    "        self.fc2 = nn.Linear(512, 256, bias=False)\n",
    "        self.fc3 = nn.Linear(256, 10, bias=False)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, stride=2)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, stride=2)  \n",
    "\n",
    "        x = x.view(-1, 7*7*128)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)  \n",
    "\n",
    "        x = F.log_softmax(x, dim=1)  \n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift Quantization operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBounderyExponents(W, b):\n",
    "    s = torch.max(torch.abs(W)).item()\n",
    "    n1 = np.floor(np.log2(4*(s/3)))\n",
    "    n2 = n1 + 1 - (2**(b - 1))/2\n",
    "    return n1, n2\n",
    "\n",
    "def getQuantizationMask(W, percentage, T):\n",
    "    w = W.view(-1)\n",
    "    t = T.view(-1)\n",
    "    idx = t == 1\n",
    "\n",
    "    numberOfWeights = w.size(dim=0)\n",
    "    numberOfQWeights = int(percentage*numberOfWeights - t[idx].size(dim=0))\n",
    "\n",
    "    t_aux = torch.Tensor(np.ones_like(T)).view(-1)\n",
    "    w = w*(t_aux - t)\n",
    "    w = torch.abs(w)\n",
    "    sorted_w, indices_w = w.sort()\n",
    "    t[indices_w[-numberOfQWeights:]] = 1\n",
    "    \n",
    "    return t.view(T.size())\n",
    "\n",
    "def quantizeWeights(W, T, n1, n2):\n",
    "    T_aux = torch.Tensor(np.ones_like(T))\n",
    "    eps = 1e-6\n",
    "    W1 = W*(T_aux - T)\n",
    "    idx = W == 0\n",
    "    W.data[idx] = eps\n",
    "\n",
    "    closestExp = torch.floor(torch.log2(torch.abs(W*4/3)))\n",
    "    Q = W1 + torch.sign(W)*(2**closestExp)*T\n",
    "\n",
    "    idx = closestExp*T < n2\n",
    "    Q[idx] = 0\n",
    "    idx = ((closestExp > n1)*T).bool()\n",
    "    Q[idx] = 2**n1\n",
    "\n",
    "    return closestExp, Q\n",
    "\n",
    "def quantize_conv_layer(W, T, percentage, number_of_bits):\n",
    "    n = T.size(dim=0)\n",
    "    m = T.size(dim=1)\n",
    "\n",
    "    n1, n2 = getBounderyExponents(W, number_of_bits)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            T[i, j, :, :] = getQuantizationMask(W[i, j, :, :], percentage, T[i, j, :, :])\n",
    "            _, W.data[i, j, :, :] = quantizeWeights(W[i, j, :, :], T[i, j, :, :], n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.tensor(np.array([\n",
    "    [0.01, 0.02, -0.2, 0.04, 0.33],\n",
    "    [0.17, -0.42, -0.33, 0.02, -0.05], \n",
    "    [0.02, 0.83, -0.03, 0.03, 0.06],\n",
    "    [-0.9, 0.07, 0.11, 0.87, -0.36], \n",
    "    [-0.73, 0.41, 0.42, 0.39, 0.47]]))\n",
    "bit_length = 4\n",
    "n1, n2 = getBounderyExponents(W, bit_length)\n",
    "print(n1, n2)\n",
    "T = torch.Tensor(np.zeros_like(W))\n",
    "T = getQuantizationMask(W, 0.5, T)\n",
    "print(T)\n",
    "_, W = quantizeWeights(W, T, n1, n2)\n",
    "\n",
    "W = torch.Tensor(np.array([\n",
    "    [0.11, 0.04, -0.7, 0.19, -0.25],\n",
    "    [0.15, -0.5, -0.25, -0.09, -0.02],\n",
    "    [-0.02, 1, -0.06, 0.21, 0.15],\n",
    "    [-1, 0.27, -0.09, 1, -0.25],\n",
    "    [-0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "]))\n",
    "\n",
    "T = getQuantizationMask(W, 0.75, T)\n",
    "_, W = quantizeWeights(W, T, n1, n2)\n",
    "print(T)\n",
    "print(W)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device initialization for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load(\"../Baseline/baseline.pth\")\n",
    "net.to(device)\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr = 1e-2, weight_decay=0)\n",
    "\n",
    "quantization_percentages = [0.5, 0.75, 0.875]\n",
    "quantization_precision = 8\n",
    "\n",
    "epochs = 5\n",
    "logs_interval = 100\n",
    "iteration = 0\n",
    "train_loss = []\n",
    "\n",
    "Tconv1 = torch.zeros_like(net.conv1.weight)\n",
    "Tconv2 = torch.zeros_like(net.conv2.weight)\n",
    "Tconv3 = torch.zeros_like(net.conv3.weight)\n",
    "Tconv4 = torch.zeros_like(net.conv4.weight)\n",
    "\n",
    "net.train()\n",
    "\n",
    "for q_stage, percentage in enumerate(quantization_percentages):\n",
    "    # quantize layers\n",
    "    quantize_conv_layer(net.conv1.weight, Tconv1, percentage, quantization_precision)\n",
    "    quantize_conv_layer(net.conv2.weight, Tconv2, percentage, quantization_precision)\n",
    "    quantize_conv_layer(net.conv3.weight, Tconv3, percentage, quantization_precision)\n",
    "    quantize_conv_layer(net.conv4.weight, Tconv4, percentage, quantization_precision)\n",
    "    \n",
    "    # correct remaining weights by training\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # setam gradienti la 0\n",
    "            Tconv1_aux = torch.ones_like(Tconv1)\n",
    "            Tconv2_aux = torch.ones_like(Tconv2)\n",
    "            Tconv3_aux = torch.ones_like(Tconv3)\n",
    "            Tconv4_aux = torch.ones_like(Tconv4)\n",
    "            net.conv1.weight.grad = net.conv1.weight.grad*(Tconv1_aux - Tconv1)\n",
    "            net.conv2.weight.grad = net.conv2.weight.grad*(Tconv2_aux - Tconv2)\n",
    "            net.conv3.weight.grad = net.conv3.weight.grad*(Tconv3_aux - Tconv3)\n",
    "            net.conv4.weight.grad = net.conv4.weight.grad*(Tconv4_aux - Tconv4)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            iteration = iteration + 1\n",
    "            if iteration % logs_interval == 0:\n",
    "                print('Quantization step: {}/{}, Train epoch:{}, batch index:{}, loss:{}'.format(\n",
    "                    q_stage + 1, len(quantization_percentages),\n",
    "                    epoch, batch_idx, loss.item()/logs_interval))\n",
    "                train_loss.append(loss.item())    \n",
    "\n",
    "quantize_conv_layer(net.conv1.weight, Tconv1, 1, quantization_precision)\n",
    "quantize_conv_layer(net.conv2.weight, Tconv2, 1, quantization_precision)\n",
    "quantize_conv_layer(net.conv3.weight, Tconv3, 1, quantization_precision)\n",
    "quantize_conv_layer(net.conv4.weight, Tconv4, 1, quantization_precision) \n",
    "\n",
    "torch.save(net, \"INQ.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "loss = 0\n",
    "correct = 0\n",
    "\n",
    "confusion_matrix = np.zeros((10, 10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = net(data)\n",
    "        loss += F.nll_loss(output, target, reduction=\"sum\").item()\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        confusion_matrix[pred.cpu()[:, 0], target.cpu()] += 1\n",
    "\n",
    "    loss = loss/len(test_loader.dataset)\n",
    "    accuracy = 100.*correct/len(test_loader.dataset)\n",
    "    print('Test set average loss: {}, accuracy: {}%'.format(loss, accuracy))\n",
    "\n",
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load(\"../Baseline/baseline.pth\")\n",
    "\n",
    "net.to(device)\n",
    "net.eval()\n",
    "loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = net(data)\n",
    "        loss += F.nll_loss(output, target, reduction=\"sum\").item()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(net, test_loader):\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "\n",
    "    correct = 0\n",
    "    loss = 0\n",
    "    confusion_matrix = np.zeros((10, 10))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = net(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            loss += F.nll_loss(output, target, reduction=\"sum\").item()\n",
    "            confusion_matrix[pred.view(-1), target] += 1\n",
    "\n",
    "    print(\"[OK] Model evaluation complete [OK]\")\n",
    "    print(\"Average loss: {:.5f}\".format(loss/len(test_loader.dataset)))\n",
    "    print(\"Test data accuracy: {:.2f}%\".format(100.*(correct/len(test_loader.dataset))))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(confusion_matrix/len(train_loader.dataset))\n",
    "    ax.set_xticks(np.arange(10))\n",
    "    ax.set_yticks(np.arange(10))\n",
    "    ax.set_xlabel(\"Truth\")\n",
    "    ax.set_ylabel(\"Predictions\")\n",
    "    ax.set_title(\"Confusion matrix\")\n",
    "    fig.set_size_inches(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Model evaluation complete [OK]\n",
      "Average loss: 0.04936\n",
      "Test data accuracy: 98.45%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = torch.load(\"../Baseline/baseline.pth\")\n",
    "\n",
    "evaluateModel(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = VGG7()\n",
    "# net.to(device)\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.1, weight_decay=0)\n",
    "# wei = torch.clone(net.conv1.weight)\n",
    "# Tconv1 = torch.zeros_like(net.conv1.weight)\n",
    "# quantize_conv_layer(net.conv1.weight, Tconv1, 0.5)\n",
    "# wei_q = torch.clone(net.conv1.weight)\n",
    "\n",
    "# net.train()\n",
    "\n",
    "# sample, lable = train_data[0]\n",
    "# lable = torch.Tensor([lable]).long()\n",
    "# optimizer.zero_grad()\n",
    "# output = net(sample)\n",
    "# loss = F.nll_loss(output, lable)\n",
    "# loss.backward()\n",
    "\n",
    "# Tconv1_aux = torch.ones_like(Tconv1)\n",
    "# net.conv1.weight.grad = net.conv1.weight.grad*(Tconv1_aux - Tconv1)\n",
    "# optimizer.step()\n",
    "\n",
    "\n",
    "# print(wei[0, 0, :, :])\n",
    "# print(Tconv1[0, 0, :, :])\n",
    "# print(wei_q[0, 0, :, :])\n",
    "# print(net.conv1.weight[0, 0, :, :])\n",
    "print(net.conv1.weight)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da9c6a45712c6b513c4a80738271fc65c25531d6aa017375b96d9ba6472bbc68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
